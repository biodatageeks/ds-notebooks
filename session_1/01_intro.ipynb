{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zajcia 1 (cz 1)\n",
    "\n",
    "Zakres:\n",
    "* Zapoznanie sie ze srodowiskiem pracy (GKE na GCP)\n",
    "* Operacje na obiektowym systemie plik贸w (GCS)\n",
    "* Interaktywna analiza rozproszonych danych przy wykorzystaniu moduu Spark Core i Spark SQL\n",
    "* Wprowadzenie moduu pandas\n",
    "* Wizualizacje przy wykorzystaniu matplotlib oraz seaborn\n",
    "\n",
    "Jzyki:\n",
    "* bash, Python, SQL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kr贸tka lista przydatnych polece bash: https://www.reddit.com/r/linux/comments/9rns12/some_linux_commands_cheatsheet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Notebook\n",
    "\n",
    "* Interaktywny notatnik dostepny poprzez przegldark.\n",
    "* Su偶y do wpisywania polece w wybranych jezykach programowania oraz opis w tzw jezyku markdown.\n",
    "* Polecenia/opis wpisujemy do kom贸rek. Kom贸rki s wykonywane przez tzw. kernel (np Python w okrelonej wersji)\n",
    "* Dziaa w tryb edycji kom贸rek + tryb wykonywania polece. (przejcie poprzez ESC i ENTER)\n",
    "* Podstawowe skr贸ty klawiaturowe: \n",
    "  * Esc/Enter\n",
    "  * strzalki\n",
    "  * ctrl-enter/shift-enter\n",
    "  * a/b/d\n",
    "  * y/m \n",
    "* Moze wykonywa polecenia powoki (bash) !  %%bash\n",
    "* Notatnik zapisywany jest w formacie ipynb (IPythonNoteBook)\n",
    "* Kolejnosc uruchomienia kom贸rek moze byc rozna.\n",
    "* Mozliwosc zatrzymania kernela i uruchomienia od nowa. \n",
    "\n",
    "Polecamy film: https://www.youtube.com/watch?v=HW29067qVWk\n",
    "\n",
    "Przykadowe kom贸rki Pythonowe i Bashowe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello agaszmurlo!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "user = os.environ.get('JUPYTERHUB_USER')\n",
    "msg = f\"Hello {user}!\"\n",
    "print (msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/ds-notebooks/session_1\n"
     ]
    }
   ],
   "source": [
    "! pwd # poka偶 aktualn scie偶k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# rodowisko Google Kubernetes Engine \\n\",\n",
      "    \"\\n\",\n",
      "    \"Logowanie kontem github. \\n\",\n",
      "    \"\\n\",\n",
      "--------------------\n",
      "   \"version\": \"3.8.5\"\n",
      "  },\n",
      "  \"notebook_test\": {\n",
      "   \"keytab_path\": \"/data/work/home/ds-lab-testuser1/ds-lab-testuser1.keytab\",\n",
      "   \"user\": \"ds-lab-testuser1\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head cloud.ipynb\n",
    "echo \"--------------------\"\n",
    "tail cloud.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kopiowanie danych do swojego katalogu domowego\n",
    "\n",
    "W katalogu `/mnt/data/datascience` znajduje sie plik kt贸ry bedzie nam dzisiaj suzyl do pracy. Nale偶y go skopiowa do swojego katalogu domowego. \n",
    "Dane pochodz z https://gdac.broadinstitute.org/ i zawieraj dane z badaniami nad mutacjami typu CNV w obrebie genu BRAC2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 376K\n",
      "drwxrwsr-x  2 jovyan users 4.0K Apr 21 13:26 .\n",
      "drwxrwsr-x 25 root   users 4.0K Apr 21 13:26 ..\n",
      "-rw-rw-r--  1 jovyan users 367K Apr 21 13:39 brca.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p ~/data     # stworz katalog data (i posrednie)\n",
    "cp /mnt/data/datascience/brca.txt ~/data  # skopiuj plik z lokalizacji do bie偶cej lokalizacji\n",
    "ls -lah   ~/data       # wylistuj zawarto bie偶cego katalogu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head ~/data/brca.txt   # poka偶 pocztek pliku\n",
    "echo                   # pusta linia\n",
    "tail ~/data/brca.txt   # poka偶 koniec pliku \n",
    "echo\n",
    "wc -l ~/data/brca.txt  # policz linie pliku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rodowisko Google Kubernetes Engine \n",
    "\n",
    "Logowanie kontem github. \n",
    "\n",
    "  Podzikowania dla Operatora Chmury Krajowej (https://chmurakrajowa.pl/) i Google Poland za udostpnienie infrastruktury i pokrycie koszt贸w wykorzystania zasob贸w podczas zaj.  \n",
    "\n",
    "\n",
    "## Kubernetes\n",
    "\n",
    "Kubernetes (k8s) to otwarta platforma do koordynacji wysoko dostpnego klastra. \n",
    "* Umo偶liwia  deklaratywn konfiguracj, automatyzacj wdra偶ania, skalowanie i autoskalowanie rozwiza.\n",
    "* Pozwala uruchamia aplikacje/narzdzie bez przypisywania ich do konkretnej maszyny. Aplikacje musz by niezale偶ne od konkretnego serwera: musz by skonteneryzowane.\n",
    "* Mo偶liwe do uruchomienia na prywatnym centrum danych, infrastrukturze hybrydowej lub chmurze publicznej.\n",
    "\n",
    "\n",
    "**Klaster Kubernetes**  \n",
    "* **Wze sterujcy (Master node)** koordynuje dziaanie klastra np. zlecanie uruchomienia aplikacji, utrzymywanie po偶danego stanu aplikacji, skalowanie aplikacji i instalowanie nowych wersji\n",
    "* **Wze roboczy (Worker node)** Na wzach uruchamiane s aplikacje. Na ka偶dym w藕le dziaa agent zarzdzajcy tym wzem i komunikujcy si z masterem Kubernetes (API). Wze zawiera tak偶e narzdzia do obsugi kontener贸w\n",
    "\n",
    "**Pod** to grupa jednego/wielu kontener贸w wraz ze wsp贸lnymi zasobami (np. dysk). Pod tworzy \"wirtualney serwer\" i mo偶e zawiera r贸偶ne kontenery aplikacji wsp贸dzielce zasoby i kontekst wykonawczy na tym samym w藕le.\n",
    "* Pod jest uruchamiany na w藕le roboczym. Wze jest maszyn robocz, fizyczn lub wirtualn, w zale偶noci od klastra. \n",
    "* Wze mo偶e zawiera wiele pod贸w. \n",
    "* Kubernetes master automatycznie zleca uruchomienie pod贸w na r贸偶nych wzach w ramach klastra. Automatyczne zlecanie uruchomienia bierze pod uwag zasoby dostpne na ka偶dym z wz贸w.\n",
    "\n",
    "![](../img/gke.png) \n",
    "\n",
    "\n",
    "## Wykorzystanie Google Cloud Storage\n",
    "\n",
    "#### Projekt\n",
    "* Wszystki dane przynale偶 do konkretnego projektu.\n",
    "* Do projektu mog mie dostp u偶ytkownicy. \n",
    "* Projekt ma zdefiniowane metody uwierzytelniajce, rozliczenia, monitorowanie etc. \n",
    "#### Kubeek (bucket)\n",
    "* Kubeek (buckket) to kontener na pliki/obiekty. \n",
    "* Nazwa Bucketu musi by unikalna w skali caej usugi u wszystkich u偶ytkownik贸w (!) \n",
    "* Kubek贸w nie mo偶na zagnie偶dza\n",
    "* W kubekach mo偶emy tworzy foldery i tam logicznie grupowa pliki.\n",
    "* Kubeek wraz z zawartoci mo偶e zosta udostpniony publicznie.\n",
    "* Kubekowi nie mo偶na zmieni nazwy lub metadanych. Trzeba go usun i stworzy ponownie.\n",
    "#### Obiekt \n",
    "* obiekty przechowywane w kubekach \n",
    "* obiekty maj zawarto oraz metadane\n",
    "* obiekty s niemodyfikowalne \n",
    "\n",
    "Do operacji na Google Storage mo偶na wykorzysta narzdzie `gsutil`: \n",
    "\n",
    "##### Operacje na kubekach\n",
    "* listowanie kubek贸w (buckets) - `ls`\n",
    "* tworzenie nowego kubeka - `mb`\n",
    "* usuwania kubeka - `rm`\n",
    "* listowanie zawartoci kubek贸w - `ls` \n",
    "* udostpnianie - `iam`\n",
    "\n",
    "##### Operacje na obiektach\n",
    "* dodawania pliku do kubeka - `cp`\n",
    "* kopiowanie - `cp`\n",
    "* usuniecie z kubeka - `cp`\n",
    "* pobranie informacji o obiekcie - `stat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operacje na kubekach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://artifacts.studiapodyplomowe.appspot.com/\n",
      "gs://bdg-lab-agaszmurlo/\n",
      "gs://bdg-lab-bwentura/\n",
      "gs://bdg-lab-gcr/\n",
      "gs://bdg-lab-karolinaow/\n",
      "gs://bdg-lab-mandrush/\n",
      "gs://bdg-lab-matdaw/\n",
      "gs://bdg-lab-michalrudko/\n",
      "gs://bdg-lab-mszelest/\n",
      "gs://bdg-lab-mwiewior/\n",
      "gs://bdg-lab-tgambin/\n",
      "gs://bdg-sequila-dev/\n",
      "gs://bucket-agaszmurlo/\n",
      "gs://bucket-aniaszczepinska/\n",
      "gs://bucket-dd004/\n",
      "gs://bucket-ds-lab-testuser1/\n",
      "gs://bucket-edugen/\n",
      "gs://bucket-karolina95/\n",
      "gs://bucket-kipk29/\n",
      "gs://bucket-lutram/\n",
      "gs://bucket-matdaw/\n",
      "gs://bucket-mp0028/\n",
      "gs://bucket-nataliawu/\n",
      "gs://bucket-t-h-i-n-k/\n",
      "gs://bucket-tgambin/\n",
      "gs://ds_labs_agaszmurlo/\n",
      "gs://edugen-common-data/\n",
      "gs://edugen-data/\n",
      "gs://edugen-lab-agaszmurlo/\n",
      "gs://edugen-lab-hallay/\n",
      "gs://edugen-lab-matdaw/\n",
      "gs://edugen-lab-tgambin/\n",
      "gs://eu.artifacts.studiapodyplomowe.appspot.com/\n",
      "gs://tbd-infra/\n",
      "gs://tbd-project/\n",
      "gs://test_agaszmurlo/\n",
      "gs://tgambin-hidden/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo $USER  # wyswietlenie nazwy uzytkownika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil mb gs://bucket-$USER  # stworzenie bucketu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -L -b gs://bucket-$JUPYTERHUB_USER # listowanie zawartoci "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil du -s  gs://bucket-$USER # ile zajmuje przestrzeni?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operacje na zawartoci kubek贸w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -r gs://bucket-$USER/ # listowanie zawartosci kubeka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp ~/work/git/ds-notebooks/README.md gs://bucket-$USER  # upload obiektu do kubeka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -r gs://bucket-$USER # listowanie zawartoci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil iam get gs://bucket-$USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil stat gs://bucket-$USER/README.md # metadane obiekty w kubeku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil iam ch allUsers:objectViewer gs://bucket-$USER # dodanie uprawnien do odczytu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po wykonaniu tego polecenia nasz kubeek staje si publiczny i mo偶emy si do niego \n",
    "http://storage.googleapis.com/bucket-NAZWA_UZYTKOWNIKA. Zawarto pliku mo偶na odczyta poprzez http://storage.googleapis.com/bucket-NAZWA_UZYTKOWNIKA/NAZWA_OBIEKTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil iam ch -d allUsers:objectViewer gs://bucket-$USER # usuniecie uprawnien do odczytu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz mo偶na ponownie zweryfikowac mo偶liwo publicznego odczytu danych z kubeka."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przeniesienie do docelowego kubeka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil cp -r gs://bucket-$USER gs://DOCELOWY_BUCKET\n",
    "gsutil rm -r gs://bucket-$USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:yellow'> ZADANIE 1 </span>\n",
    "a) Utw贸rz plik zawierajcy aktualn date i godzin. \n",
    "b) Udostpnij plik publicznie na google storage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:yellow'> ZADANIE 2 </span>\n",
    "Skopiuj plik z lokalizacji `gs://bucket-$USER` do lokalizacji `gs://bdg-lab-$USER`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pobranie pliku z powrotem na lokalny dysk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://bucket-agaszmurlo/brca.txt...\n",
      "/ [1 files][366.8 KiB/366.8 KiB]                                                \n",
      "Operation completed over 1 objects/366.8 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp gs://bucket-$USER/brca.txt .  # gdzie sie zapisal ten plik?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Spark\n",
    "\n",
    "* Apache Spark platforma og贸lnego zastosowania, opensource, do przetwarzania duzych zbiorow danych.\n",
    "* Posiada  API dla jzyk贸w programowania: Scala, Python i R. \n",
    "* Przetwarzanie w Spark przetwarzanie jest wykonywane w wikszoci  wprost w pamici operacyjnej.\n",
    "* Przeznaczenie: do uruchamiania  aplikacji i skrypt贸w z wykorzystaniem uczenia maszynowego lub interaktywnych kwerend.\n",
    "* Spark ten wspiera SQL (typ DataFrames), przetwarzanie strumieniowe oraz przetwarzanie graf贸w.\n",
    "* Integracja z lokaln pamici masow, rozproszonymi lub obiektowymi systemu plik贸w.\n",
    "* Spark mo偶na uruchami na pojedynczej maszynie na rodowisku klastrowym, lub w chmurze. \n",
    "\n",
    "Zakres na dzisiejsze laboratorium:\n",
    "* stworzenie sesji Spark\n",
    "* zaczytanie danych z pliku tekstowego\n",
    "* kwerendy na danych\n",
    "\n",
    "Bedziemy korzystac z pliku ktory zapisalismy na HDFS w pierwszej czesci cwiczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls /user/${USER}/external/data # Sprawdzmy czy plik znajduje si w katalogu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie sesji Sparkowej\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agaszmurlo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "user_name = os.environ.get('USER')\n",
    "print(user_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    ".config(\"spark.executor.instances\", \"1\") \\\n",
    ".config(\"spark.executor.memory\", \"1g\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rczne utworzenie zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = spark.createDataFrame(\n",
    "    [(123, 'Jan Kowalski', 'jan@kowalski.pl'), \n",
    "     (124, 'Anna Nowak', 'anna@nowak.pl'), \n",
    "     (125, 'Janusz Kowalski', 'janusz@kowalski.pl'), \n",
    "     (126, 'Anita Nowak', 'anita@nowak.pl')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+------------------+\n",
      "| _1|             _2|                _3|\n",
      "+---+---------------+------------------+\n",
      "|123|   Jan Kowalski|   jan@kowalski.pl|\n",
      "|124|     Anna Nowak|     anna@nowak.pl|\n",
      "|125|Janusz Kowalski|janusz@kowalski.pl|\n",
      "|126|    Anita Nowak|    anita@nowak.pl|\n",
      "+---+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = false)\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = spark.createDataFrame(\n",
    "    [(123, 'Jan Kowalski', 'jan@kowalski.pl'), \n",
    "     (124, 'Anna Nowak', 'anna@nowak.pl'), \n",
    "     (125, 'Janusz Kowalski', 'janusz@kowalski.pl'), \n",
    "     (126, 'Anita Nowak', 'anita@nowak.pl')],\n",
    "    schema='id int not null, name string, email string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+------------------+\n",
      "| id|           name|             email|\n",
      "+---+---------------+------------------+\n",
      "|123|   Jan Kowalski|   jan@kowalski.pl|\n",
      "|124|     Anna Nowak|     anna@nowak.pl|\n",
      "|125|Janusz Kowalski|janusz@kowalski.pl|\n",
      "|126|    Anita Nowak|    anita@nowak.pl|\n",
      "+---+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = false)\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_users.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Wczytanie danych\n",
    "Zazwyczaj dane mamy przechowane na zewntrz naszego notatnika (np. w pliku) i nale偶y je odczyta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = f'gs://bdg-lab-{user_name}/brca.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load(input_path, format=\"csv\", sep=\"\\t\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charakterystyka danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type (df)                 # jaki jest typ danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.explain()              # fizyczny plan wykonania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.explain(True)          # logiczny i fizyczny plan wykonania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions() # liczba partycji (blok贸w danych)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()          # schemat danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()                # wymiary (liczba wierszy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)           # wymiary (liczba kolumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().show()      # poka偶 podsumowanie danych w tabeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(\"Chromosome\").show() # poka偶 podsumowanie danych w kolumnie "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odczyt danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()                    # poka偶 20 wierszy danych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(10, truncate=False) # poka偶 10 wierszy, nie skracaj danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"Sample\").show()  # poka偶 tylko kolumne sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"Chromosome\", \"Start\", \"End\").show() # poka偶 kolumny chromosome, start i end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chrom = df.select(df.Chromosome).distinct() # stworz nowy DF zawierajacy tylko unikalne wartosci chromosomow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chrom.count()                     # policz wiersze w nowym DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\"Chromosome > 21\").show() # pokaz dane spelniajace warunek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\"Chromosome > 21\").explain()  # pokaz plan wykonania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\"Chromosome > 21 and Segment_Mean > 0\").show() # pokaz dane spelniajace warunki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grupowanie i funkcje agregujce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"Chromosome\").count().show()   # dokonaj grupowania po chromosomie i policz rekordy w grupie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"Chromosome\").avg(\"Segment_Mean\").show() # dokonaj grupowania po chromosomie i policz srednia wartosc segment_mean w grupie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pogrupuj dane wzgledem probki i chromosomu, policz rekordy w grupie\n",
    "df.groupBy(\"Sample\",\"Chromosome\").count().orderBy(asc(\"Sample\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolumny wyliczane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn (\"Length\", col(\"End\") - col(\"Start\")).show() # dodaj kolumne dlugosc jako end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn (\"Material\", lit(\"DNA\")).show()     # dodaj kolumne o stalej wartosci 'DNA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn (\"Chromosome2\", concat(lit(\"chr\"), col(\"Chromosome\"))).show() # dodaj kolumne z konkatencja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Chromosome\").show()  # usun kolumne Chromosome. \n",
    "# Czy DF zostaa pozbawiona kolumny na trwale?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zapis wynik贸w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.withColumn (\"Chromosome2\", concat(lit(\"chr\"), col(\"Chromosome\")))  # dodaj kolumne z konkatenacja i zapisz do nowego DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'gs://bdg-lab-{user_name}/brca2.txt'\n",
    "df2.write.format(\"csv\").save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://bdg-lab-agaszmurlo/brca.txt\n",
      "gs://bdg-lab-agaszmurlo/brca2.txt/\n",
      "gs://bdg-lab-agaszmurlo/mlflow/\n",
      "gs://bdg-lab-agaszmurlo/survey/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls gs://bdg-lab-$USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample\tChromosome\tStart\tEnd\tNum_Probes\tSegment_Mean\n",
      "TCGA-A2-A0EU-10A-01D-A060-02\t1\t10209\t2583075\tNA\t-0.210121164888764\n",
      "TCGA-A2-A0EU-10A-01D-A060-02\t1\t2583076\t249240606\tNA\t-0.101789555120838\n",
      "TCGA-A2-A0EU-10A-01D-A060-02\t2\t10002\t243189359\tNA\t-0.337963741969504\n",
      "TCGA-A2-A0EU-10A-01D-A060-02\t3\t60175\t162511435\tNA\t-0.0850647472883194\n",
      "TCGA-A2-A0EU-10A-01D-A060-02\t3\t162511436\t162626067\tNA\t0.42309157125509\n",
      "TCGA-A2-A0EU-10A-01D-A060-02\t3\t162626068\t197962416\tNA\t-0.0962225847981023\n",
      "TCGA-A2-A0EU-10A-01D-A060-02\t4\t69223\t191014397\tNA\t-0.0713350286479217\n",
      "TCGA-A2-A0EU-10A-01D-A060-02\t5\t11770\t180905246\tNA\t0.176064461471459\n",
      "TCGA-A2-A0EU-10A-01D-A060-02\t6\t63815\t171050932\tNA\t-0.0895478602860139\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat gs://bdg-lab-$USER/brca.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:yellow'> ZADANIE 3</span>\n",
    "\n",
    "a) Ile jest unikalnych danych pr贸bek w tym zbiorze danych?\n",
    "\n",
    "b) Poka偶 nazw pr贸bki, numer chromosomu, pocztek i koniec segmentu dla segment贸w wystpujcych na chromosomie 21,22,23 i majcych startow pozycjwiksz ni偶 10000000. \n",
    "\n",
    "c) Ile wystpuje wierszy dla ka偶dej z pr贸bki? Poka偶 wynik z pen nazw pr贸bki. Zapisz wynik do pliku na GCS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "notebook_test": {
   "keytab_path": "/data/work/home/ds-lab-testuser1/ds-lab-testuser1.keytab",
   "user": "ds-lab-testuser1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
