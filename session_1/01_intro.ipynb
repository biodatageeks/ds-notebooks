{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zajcia 1 (cz 1)\n",
    "\n",
    "Zakres:\n",
    "* Zapoznanie sie ze srodowiskiem pracy (GKE na GCP)\n",
    "* Operacje na obiektowym systemie plik贸w (GCS)\n",
    "* Interaktywna analiza rozproszonych danych przy wykorzystaniu moduu Spark Core i Spark SQL\n",
    "* Wprowadzenie moduu pandas\n",
    "* Wizualizacje przy wykorzystaniu matplotlib oraz seaborn\n",
    "\n",
    "Jzyki:\n",
    "* bash, Python, SQL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kr贸tka lista przydatnych polece bash: https://www.reddit.com/r/linux/comments/9rns12/some_linux_commands_cheatsheet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Notebook\n",
    "\n",
    "* Interaktywny notatnik dostepny poprzez przegldark.\n",
    "* Su偶y do wpisywania polece w wybranych jezykach programowania oraz opis w tzw jezyku markdown.\n",
    "* Polecenia/opis wpisujemy do kom贸rek. Kom贸rki s wykonywane przez tzw. kernel (np Python w okrelonej wersji)\n",
    "* Dziaa w tryb edycji kom贸rek + tryb wykonywania polece. (przejcie poprzez ESC i ENTER)\n",
    "* Podstawowe skr贸ty klawiaturowe: \n",
    "  * Esc/Enter\n",
    "  * strzalki\n",
    "  * ctrl-enter/shift-enter\n",
    "  * a/b/d\n",
    "  * y/m \n",
    "* Moze wykonywa polecenia powoki (bash) !  %%bash\n",
    "* Notatnik zapisywany jest w formacie ipynb (IPythonNoteBook)\n",
    "* Kolejnosc uruchomienia kom贸rek moze byc rozna.\n",
    "* Mozliwosc zatrzymania kernela i uruchomienia od nowa. \n",
    "\n",
    "Polecamy film: https://www.youtube.com/watch?v=HW29067qVWk\n",
    "\n",
    "Przykadowe kom贸rki Pythonowe i Bashowe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "user = os.environ.get('USER')\n",
    "msg = f\"Hello {user}!\"\n",
    "print (msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd # poka偶 aktualn scie偶k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head 01_intro.ipynb\n",
    "echo \"--------------------\"\n",
    "tail 01_intro.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kopiowanie danych do swojego katalogu domowego\n",
    "\n",
    "W katalogu `/mnt/data/datascience` znajduje sie plik kt贸ry bedzie nam dzisiaj suzyl do pracy. Nale偶y go skopiowa do swojego katalogu domowego. \n",
    "Dane pochodz z https://gdac.broadinstitute.org/ i zawieraj dane z badaniami nad mutacjami typu CNV w obrebie genu BRAC2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ~/data     # stworz katalog data (i posrednie)\n",
    "cp /mnt/data/datascience/brca.txt ~/data  # skopiuj plik z lokalizacji do bie偶cej lokalizacji\n",
    "ls -lah   ~/data       # wylistuj zawarto bie偶cego katalogu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head ~/data/brca.txt   # poka偶 pocztek pliku\n",
    "echo                   # pusta linia\n",
    "tail ~/data/brca.txt   # poka偶 koniec pliku \n",
    "echo\n",
    "wc -l ~/data/brca.txt  # policz linie pliku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rodowisko Google Kubernetes Engine \n",
    "\n",
    "Logowanie kontem github. \n",
    "\n",
    "  Podzikowania dla Operatora Chmury Krajowej (https://chmurakrajowa.pl/) i Google Poland za udostpnienie infrastruktury i pokrycie koszt贸w wykorzystania zasob贸w podczas zaj.  \n",
    "\n",
    "\n",
    "## Kubernetes\n",
    "\n",
    "Kubernetes (k8s) to otwarta platforma do koordynacji wysoko dostpnego klastra. \n",
    "* Umo偶liwia  deklaratywn konfiguracj, automatyzacj wdra偶ania, skalowanie i autoskalowanie rozwiza.\n",
    "* Pozwala uruchamia aplikacje/narzdzie bez przypisywania ich do konkretnej maszyny. Aplikacje musz by niezale偶ne od konkretnego serwera: musz by skonteneryzowane.\n",
    "* Mo偶liwe do uruchomienia na prywatnym centrum danych, infrastrukturze hybrydowej lub chmurze publicznej.\n",
    "\n",
    "\n",
    "**Klaster Kubernetes**  \n",
    "* **Wze sterujcy (Master node)** koordynuje dziaanie klastra np. zlecanie uruchomienia aplikacji, utrzymywanie po偶danego stanu aplikacji, skalowanie aplikacji i instalowanie nowych wersji\n",
    "* **Wze roboczy (Worker node)** Na wzach uruchamiane s aplikacje. Na ka偶dym w藕le dziaa agent zarzdzajcy tym wzem i komunikujcy si z masterem Kubernetes (API). Wze zawiera tak偶e narzdzia do obsugi kontener贸w\n",
    "\n",
    "**Pod** to grupa jednego/wielu kontener贸w wraz ze wsp贸lnymi zasobami (np. dysk). Pod tworzy \"wirtualney serwer\" i mo偶e zawiera r贸偶ne kontenery aplikacji wsp贸dzielce zasoby i kontekst wykonawczy na tym samym w藕le.\n",
    "* Pod jest uruchamiany na w藕le roboczym. Wze jest maszyn robocz, fizyczn lub wirtualn, w zale偶noci od klastra. \n",
    "* Wze mo偶e zawiera wiele pod贸w. \n",
    "* Kubernetes master automatycznie zleca uruchomienie pod贸w na r贸偶nych wzach w ramach klastra. Automatyczne zlecanie uruchomienia bierze pod uwag zasoby dostpne na ka偶dym z wz贸w.\n",
    "\n",
    "![](../img/gke.png) \n",
    "\n",
    "\n",
    "## Wykorzystanie Google Cloud Storage\n",
    "\n",
    "#### Projekt\n",
    "* Wszystki dane przynale偶 do konkretnego projektu.\n",
    "* Do projektu mog mie dostp u偶ytkownicy. \n",
    "* Projekt ma zdefiniowane metody uwierzytelniajce, rozliczenia, monitorowanie etc. \n",
    "#### Kubeek (bucket)\n",
    "* Kubeek (buckket) to kontener na pliki/obiekty. \n",
    "* Nazwa Bucketu musi by unikalna w skali caej usugi u wszystkich u偶ytkownik贸w (!) \n",
    "* Kubek贸w nie mo偶na zagnie偶dza\n",
    "* W kubekach mo偶emy tworzy foldery i tam logicznie grupowa pliki.\n",
    "* Kubeek wraz z zawartoci mo偶e zosta udostpniony publicznie.\n",
    "* Kubekowi nie mo偶na zmieni nazwy lub metadanych. Trzeba go usun i stworzy ponownie.\n",
    "#### Obiekt \n",
    "* obiekty przechowywane w kubekach \n",
    "* obiekty maj zawarto oraz metadane\n",
    "* obiekty s niemodyfikowalne \n",
    "\n",
    "Do operacji na Google Storage mo偶na wykorzysta narzdzie `gsutil`: \n",
    "\n",
    "##### Operacje na kubekach\n",
    "* listowanie kubek贸w (buckets) - `ls`\n",
    "* tworzenie nowego kubeka - `mb`\n",
    "* usuwania kubeka - `rm`\n",
    "* listowanie zawartoci kubek贸w - `ls` \n",
    "* udostpnianie - `iam`\n",
    "\n",
    "##### Operacje na obiektach\n",
    "* dodawania pliku do kubeka - `cp`\n",
    "* kopiowanie - `cp`\n",
    "* usuniecie z kubeka - `cp`\n",
    "* pobranie informacji o obiekcie - `stat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operacje na kubekach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo $USER  # wyswietlenie nazwy uzytkownika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil mb gs://bucket-$USER  # stworzenie bucketu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls gs://bucket-$USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil du -s  gs://bucket-$USER # ile zajmuje przestrzeni?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -L -b gs://bucket-$USER # listowanie zawartoci "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operacje na zawartoci kubek贸w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -r gs://bucket-$USER/ # listowanie zawartosci kubeka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp ~/work/git/ds-notebooks/README.md gs://bucket-$USER  # upload obiektu do kubeka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -r gs://bucket-$USER # listowanie zawartoci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil iam get gs://bucket-$USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil stat gs://bucket-$USER/README.md # metadane obiektu w kubeku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil iam ch allUsers:objectViewer gs://bucket-$USER # dodanie uprawnien do odczytu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po wykonaniu tego polecenia nasz kubeek staje si publiczny i mo偶emy si do niego \n",
    "http://storage.googleapis.com/bucket-NAZWA_UZYTKOWNIKA. Zawarto pliku mo偶na odczyta poprzez http://storage.googleapis.com/bucket-NAZWA_UZYTKOWNIKA/NAZWA_OBIEKTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil iam ch -d allUsers:objectViewer gs://bucket-$USER # usuniecie uprawnien do odczytu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz mo偶na ponownie zweryfikowac mo偶liwo publicznego odczytu danych z kubeka."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przeniesienie do docelowego kubeka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:yellow'> ZADANIE 1 </span>\n",
    "Wgraj plik brca.txt do kubeka `gs://bdg-lab-$USER`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:yellow'> ZADANIE 2 </span>\n",
    "a) Utw贸rz plik zawierajcy aktualn date i godzin. \n",
    "b) Udostpnij plik publicznie na google storage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pobranie pliku z powrotem na lokalny dysk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp gs://bdg-lab-$USER/brca.txt .  # gdzie sie zapisal ten plik?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Spark\n",
    "\n",
    "* Apache Spark platforma og贸lnego zastosowania, opensource, do przetwarzania duzych zbiorow danych.\n",
    "* Posiada  API dla jzyk贸w programowania: Scala, Python i R. \n",
    "* Przetwarzanie w Spark przetwarzanie jest wykonywane w wikszoci  wprost w pamici operacyjnej.\n",
    "* Przeznaczenie: do uruchamiania  aplikacji i skrypt贸w z wykorzystaniem uczenia maszynowego lub interaktywnych kwerend.\n",
    "* Spark ten wspiera SQL (typ DataFrames), przetwarzanie strumieniowe oraz przetwarzanie graf贸w.\n",
    "* Integracja z lokaln pamici masow, rozproszonymi lub obiektowymi systemu plik贸w.\n",
    "* Spark mo偶na uruchami na pojedynczej maszynie na rodowisku klastrowym, lub w chmurze. \n",
    "\n",
    "Zakres na dzisiejsze laboratorium:\n",
    "* stworzenie sesji Spark\n",
    "* zaczytanie danych z pliku tekstowego\n",
    "* kwerendy na danych\n",
    "\n",
    "Bedziemy korzystac z pliku ktory zapisalismy na GCS w pierwszej czesci cwiczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -r gs://bdg-lab-$USER/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie sesji Sparkowej\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    ".config(\"spark.executor.instances\", \"1\") \\\n",
    ".config(\"spark.executor.memory\", \"1g\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    ".config(\"spark.executor.instances\", \"1\") \\\n",
    ".config(\"spark.executor.memory\", \"1g\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rczne utworzenie zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stworzenie rozproszonego DF na podstawie podanej listy krotek \n",
    "df_users = spark.createDataFrame(\n",
    "    [(123, 'Jan Kowalski', 'jan@kowalski.pl'), \n",
    "     (124, 'Anna Nowak', 'anna@nowak.pl'), \n",
    "     (125, 'Janusz Kowalski', 'janusz@kowalski.pl'), \n",
    "     (126, 'Anita Nowak', 'anita@nowak.pl')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = spark.createDataFrame(\n",
    "    [(123, 'Jan Kowalski', 'jan@kowalski.pl'), \n",
    "     (124, 'Anna Nowak', 'anna@nowak.pl'), \n",
    "     (125, 'Janusz Kowalski', 'janusz@kowalski.pl'), \n",
    "     (126, 'Anita Nowak', 'anita@nowak.pl')],\n",
    "    schema='id int not null, name string, email string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Wczytanie danych\n",
    "Zazwyczaj dane mamy przechowane na zewntrz naszego notatnika (np. w pliku) i nale偶y je odczyta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "user_name = os.environ.get('USER')\n",
    "print(user_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = f'gs://bdg-lab-{user_name}/brca.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load(input_path, format=\"csv\", sep=\"\\t\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charakterystyka danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type (df)                 # jaki jest typ danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.explain()              # fizyczny plan wykonania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.explain(True)          # logiczny i fizyczny plan wykonania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions() # liczba partycji (blok贸w danych)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()          # schemat danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()                # wymiary (liczba wierszy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)           # wymiary (liczba kolumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().show()      # poka偶 podsumowanie danych w tabeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(\"Chromosome\").show() # poka偶 podsumowanie danych w kolumnie "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odczyt danych\n",
    "Z wykorzystaniem API DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()                    # poka偶 20 wierszy danych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(10, truncate=False) # poka偶 10 wierszy, nie skracaj danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"Sample\").show()  # poka偶 tylko kolumne sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"Chromosome\", \"Start\", \"End\").show() # poka偶 kolumny chromosome, start i end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chrom = df.select(df.Chromosome).distinct() # stworz nowy DF zawierajacy tylko unikalne wartosci chromosomow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chrom.count()                     # policz wiersze w nowym DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\"Chromosome > 21\").show() # pokaz dane spelniajace warunek (przy uzyciu filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(\"Chromosome > 21\").show() # pokaz dane spelniajace warunek (przy uzyciu when)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\"Chromosome > 21\").explain()  # pokaz plan wykonania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\"Chromosome > 21 and Segment_Mean > 0\").show() # pokaz dane spelniajace warunki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grupowanie i funkcje agregujce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"Chromosome\").count().show()   # dokonaj grupowania po chromosomie i policz rekordy w grupie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"Chromosome\").avg(\"Segment_Mean\").show() # dokonaj grupowania po chromosomie i policz srednia wartosc segment_mean w grupie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pogrupuj dane wzgledem probki i chromosomu, policz rekordy w grupie\n",
    "df.groupBy(\"Sample\",\"Chromosome\").count().orderBy(asc(\"Sample\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolumny wyliczane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn (\"Length\", col(\"End\") - col(\"Start\")).show() # dodaj kolumne dlugosc jako end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn (\"Material\", lit(\"DNA\")).show()     # dodaj kolumne o stalej wartosci 'DNA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn (\"Chromosome2\", concat(lit(\"chr\"), col(\"Chromosome\"))).show() # dodaj kolumne z konkatencja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Chromosome\").show()  # usun kolumne Chromosome. \n",
    "# Czy DF zostaa pozbawiona kolumny na trwale?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zapis wynik贸w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.withColumn (\"Chromosome2\", concat(lit(\"chr\"), col(\"Chromosome\")))  # dodaj kolumne z konkatenacja i zapisz do nowego DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'gs://bdg-lab-{user_name}/brca2.txt'\n",
    "df2.write.format(\"csv\").mode(\"overwrite\").save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls gs://bdg-lab-$USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cat gs://bdg-lab-$USER/brca.txt | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:yellow'> ZADANIE 3</span>\n",
    "\n",
    "a) Ile jest unikalnych danych pr贸bek w tym zbiorze danych?\n",
    "\n",
    "b) Poka偶 nazw pr贸bki, numer chromosomu, pocztek i koniec segmentu dla segment贸w wystpujcych na chromosomie 21,22,23 i majcych startow pozycjwiksz ni偶 10000000. \n",
    "\n",
    "c) Ile wystpuje wierszy dla ka偶dej z pr贸bki? Poka偶 wynik z pen nazw pr贸bki. Zapisz wynik do pliku na GCS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "notebook_test": {
   "keytab_path": "/data/work/home/ds-lab-testuser1/ds-lab-testuser1.keytab",
   "user": "ds-lab-testuser1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
